import streamlit as st
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report

st.title("Fake News Detection using NLP")

st.write("Upload your dataset for training the model:")
uploaded_file = st.file_uploader("Choose a CSV file", type="csv")

if uploaded_file is not None:
    data = pd.read_csv(uploaded_file)

    # Checking for missing values
    data = data.dropna()

    # Splitting the dataset into training and testing sets
    X = data['text']  # Text column
    y = data['label']  # Label column (fake or real)

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # Feature extraction using TF-IDF
    tfidf_vectorizer = TfidfVectorizer(max_df=0.7, min_df=0.1, stop_words='english')
    X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)
    X_test_tfidf = tfidf_vectorizer.transform(X_test)

    # Model training with Logistic Regression
    model = LogisticRegression()
    model.fit(X_train_tfidf, y_train)

    # Prediction and evaluation
    y_pred = model.predict(X_test_tfidf)
    accuracy = accuracy_score(y_test, y_pred)

    st.write(f"Model Accuracy: {accuracy * 100:.2f}%")

    st.write("\nClassification Report:\n")
    st.text(classification_report(y_test, y_pred))

    st.write("Try with your own text:")
    user_input = st.text_area("Enter news text:")

    if st.button("Check if Fake or Real"):
        user_tfidf = tfidf_vectorizer.transform([user_input])
        prediction = model.predict(user_tfidf)
        st.write(f"Prediction: {'Fake News' if prediction[0] == 'fake' else 'Real News'}")


The Fake News Detection project is now upgraded to a complete Streamlit web app with an interactive interface.

Would you like me to guide you on how to deploy it online (e.g., on Streamlit Cloud or Hugging Face Spaces) for public access?
